{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Helm 101 \u00b6 Helm is often described as the Kubernetes application package manager. So, what does Helm give you over using kubectl directly? Objectives \u00b6 These labs provide an insight on the advantages of using Helm over using Kubernetes directly through kubectl . In several of the labs there are two scenarios. The first scenario gives an example of how to perform the task using kubectl , the second scenario, using helm . When you complete all the labs, you'll: Understand the core concepts of Helm Understand the advantages of deployment using Helm over Kubernetes directly, looking at: Application management Updates Configuration Revision management Repositories and chart sharing Prerequisites \u00b6 Have a running Kubernetes cluster. See the IBM Cloud Kubernetes Service or Kubernetes Getting Started Guide for details about creating a cluster. Have Helm installed and initialized with the Kubernetes cluster. See Installing Helm on IBM Cloud Kubernetes Service or the Helm Quickstart Guide for getting started with Helm. Helm Overview \u00b6 Helm is a tool that streamlines installation and management of Kubernetes applications. It uses a packaging format called \"charts\", which are a collection of files that describe Kubernetes resources. It can run anywhere (laptop, CI/CD, etc.) and is available for various operating systems, like OSX, Linux and Windows. Helm 3 pivoted from the Helm 2 client-server architecture to a client architecture. The client is still called helm and, there is an improved Go library which encapsulates the Helm logic so that it can be leveraged by different clients. The client is a CLI which users interact with to perform different operations like install/upgrade/delete etc. The client interacts with the Kubernetes API server and the chart repository. It renders Helm template files into Kubernetes manifest files which it uses to perform operations on the Kubernetes cluster via the Kubernetes API. See the Helm Architecture for more details. A chart is organized as a collection of files inside of a directory where the directory name is the name of the chart. It contains template YAML files which facilitates providing configuration values at runtime and eliminates the need of modifying YAML files. These templates provide programming logic as they are based on the Go template language , functions from the Sprig lib and other specialized functions . The chart repository is a location where packaged charts can be stored and shared. This is akin to the image repository in Docker. Refer to The Chart Repository Guide for more details. Helm Abstractions \u00b6 Helm terms: Chart - It contains all of the resource definitions necessary to run an application, tool, or service inside of a Kubernetes cluster. A chart is basically a package of pre-configured Kubernetes resources. Config - Contains configuration information that can be merged into a packaged chart to create a releasable object. helm - Helm client. It renders charts into manifest files. It interacts directly with the Kubernetes API server to install, upgrade, query, and remove Kubernetes resources. Release - An instance of a chart running in a Kubernetes cluster. Repository - Place where charts reside and can be shared with others. To get started, head on over to Lab 1 .","title":"About the workshop"},{"location":"#helm-101","text":"Helm is often described as the Kubernetes application package manager. So, what does Helm give you over using kubectl directly?","title":"Helm 101"},{"location":"#objectives","text":"These labs provide an insight on the advantages of using Helm over using Kubernetes directly through kubectl . In several of the labs there are two scenarios. The first scenario gives an example of how to perform the task using kubectl , the second scenario, using helm . When you complete all the labs, you'll: Understand the core concepts of Helm Understand the advantages of deployment using Helm over Kubernetes directly, looking at: Application management Updates Configuration Revision management Repositories and chart sharing","title":"Objectives"},{"location":"#prerequisites","text":"Have a running Kubernetes cluster. See the IBM Cloud Kubernetes Service or Kubernetes Getting Started Guide for details about creating a cluster. Have Helm installed and initialized with the Kubernetes cluster. See Installing Helm on IBM Cloud Kubernetes Service or the Helm Quickstart Guide for getting started with Helm.","title":"Prerequisites"},{"location":"#helm-overview","text":"Helm is a tool that streamlines installation and management of Kubernetes applications. It uses a packaging format called \"charts\", which are a collection of files that describe Kubernetes resources. It can run anywhere (laptop, CI/CD, etc.) and is available for various operating systems, like OSX, Linux and Windows. Helm 3 pivoted from the Helm 2 client-server architecture to a client architecture. The client is still called helm and, there is an improved Go library which encapsulates the Helm logic so that it can be leveraged by different clients. The client is a CLI which users interact with to perform different operations like install/upgrade/delete etc. The client interacts with the Kubernetes API server and the chart repository. It renders Helm template files into Kubernetes manifest files which it uses to perform operations on the Kubernetes cluster via the Kubernetes API. See the Helm Architecture for more details. A chart is organized as a collection of files inside of a directory where the directory name is the name of the chart. It contains template YAML files which facilitates providing configuration values at runtime and eliminates the need of modifying YAML files. These templates provide programming logic as they are based on the Go template language , functions from the Sprig lib and other specialized functions . The chart repository is a location where packaged charts can be stored and shared. This is akin to the image repository in Docker. Refer to The Chart Repository Guide for more details.","title":"Helm Overview"},{"location":"#helm-abstractions","text":"Helm terms: Chart - It contains all of the resource definitions necessary to run an application, tool, or service inside of a Kubernetes cluster. A chart is basically a package of pre-configured Kubernetes resources. Config - Contains configuration information that can be merged into a packaged chart to create a releasable object. helm - Helm client. It renders charts into manifest files. It interacts directly with the Kubernetes API server to install, upgrade, query, and remove Kubernetes resources. Release - An instance of a chart running in a Kubernetes cluster. Repository - Place where charts reside and can be shared with others. To get started, head on over to Lab 1 .","title":"Helm Abstractions"},{"location":"SUMMARY/","text":"Summary \u00b6 Workshop \u00b6 Lab 0 Lab 1 Lab 2 Lab 3 Lab 4 Resources \u00b6 IBM Developer","title":"Summary"},{"location":"SUMMARY/#summary","text":"","title":"Summary"},{"location":"SUMMARY/#workshop","text":"Lab 0 Lab 1 Lab 2 Lab 3 Lab 4","title":"Workshop"},{"location":"SUMMARY/#resources","text":"IBM Developer","title":"Resources"},{"location":"Lab0/","text":"Lab 0. Installing Helm on IBM Cloud Kubernetes Service \u00b6 The Helm client ( helm ) can be installed from source or pre-built binary releases. In this lab, we are going to use the pre-built binary release (Linux amd64) from the Helm community. Refer to the Helm install docs for more details. Prerequisites \u00b6 Create a Kubernetes cluster with IBM Cloud Kubernetes Service , following the steps to also configure the IBM Cloud CLI with the Kubernetes Service plug-in. Installing the Helm Client (helm) \u00b6 Download the latest release of Helm v3 for your environment, the steps below are for Linux amd64 , adjust the examples as needed for your environment. Unpack it: $ tar -zxvf helm-v3.<x>.<y>-linux-amd64.tgz . Find the helm binary in the unpacked directory, and move it to its desired location: mv linux-amd64/helm /usr/local/bin/helm . It is best if the location you copy to is pathed, as it avoids having to path the helm commands. The Helm client is now installed and can be tested with the command, helm help . Conclusion \u00b6 You are now ready to start using Helm.","title":"Lab 0. Installing Helm on IKS"},{"location":"Lab0/#lab-0-installing-helm-on-ibm-cloud-kubernetes-service","text":"The Helm client ( helm ) can be installed from source or pre-built binary releases. In this lab, we are going to use the pre-built binary release (Linux amd64) from the Helm community. Refer to the Helm install docs for more details.","title":"Lab 0. Installing Helm on IBM Cloud Kubernetes Service"},{"location":"Lab0/#prerequisites","text":"Create a Kubernetes cluster with IBM Cloud Kubernetes Service , following the steps to also configure the IBM Cloud CLI with the Kubernetes Service plug-in.","title":"Prerequisites"},{"location":"Lab0/#installing-the-helm-client-helm","text":"Download the latest release of Helm v3 for your environment, the steps below are for Linux amd64 , adjust the examples as needed for your environment. Unpack it: $ tar -zxvf helm-v3.<x>.<y>-linux-amd64.tgz . Find the helm binary in the unpacked directory, and move it to its desired location: mv linux-amd64/helm /usr/local/bin/helm . It is best if the location you copy to is pathed, as it avoids having to path the helm commands. The Helm client is now installed and can be tested with the command, helm help .","title":"Installing the Helm Client (helm)"},{"location":"Lab0/#conclusion","text":"You are now ready to start using Helm.","title":"Conclusion"},{"location":"Lab1/","text":"Lab 1. Deploy with Helm \u00b6 Let's investigate how Helm can help us focus on other things by letting a chart do the work for us. We'll first deploy an application to a Kubernetes cluster by using kubectl and then show how we can offload the work to a chart by deploying the same app with Helm. The application is the Guestbook App , which is a sample multi-tier web application. Scenario 1: Deploy the application using kubectl \u00b6 In this part of the lab, we will deploy the application using the Kubernetes client kubectl . We will use Version 1 of the app for deploying here. If you already have a copy of the guestbook application installed from the kube101 lab , skip this section and go the helm example in Scenario 2 . Clone the Guestbook App repo to get the files: git clone https://github.com/IBM/guestbook.git Use the configuration files in the cloned Git repository to deploy the containers and create services for them by using the following commands: $ cd guestbook/v1 $ kubectl create -f redis-master-deployment.yaml deployment.apps/redis-master created $ kubectl create -f redis-master-service.yaml service/redis-master created $ kubectl create -f redis-slave-deployment.yaml deployment.apps/redis-slave created $ kubectl create -f redis-slave-service.yaml service/redis-slave created $ kubectl create -f guestbook-deployment.yaml deployment.apps/guestbook-v1 created $ kubectl create -f guestbook-service.yaml service/guestbook created Refer to the guestbook README for more details. View the guestbook: You can now play with the guestbook that you just created by opening it in a browser (it might take a few moments for the guestbook to come up). * **Local Host:** If you are running Kubernetes locally, view the guestbook by navigating to `http://localhost:3000` in your browser. * **Remote Host:** 1. To view the guestbook on a remote host, locate the external IP and port of the load balancer in the **EXTERNAL-IP** and **PORTS** columns of the `$ kubectl get services` output. ```console $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE guestbook LoadBalancer 172.21.252.107 50.23.5.136 3000:31838/TCP 14m redis-master ClusterIP 172.21.97.222 <none> 6379/TCP 14m redis-slave ClusterIP 172.21.43.70 <none> 6379/TCP 14m ......... ``` In this scenario the URL is `http://50.23.5.136:31838`. Note: If no external IP is assigned, then you can get the external IP with the following command: ```console $ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME 10.47.122.98 Ready <none> 1h v1.10.11+IKS 173.193.92.112 Ubuntu 16.04.5 LTS 4.4.0-141-generic docker://18.6.1 ``` In this scenario the URL is `http://173.193.92.112:31838`. 2. Navigate to the output given (for example `http://50.23.5.136:31838`) in your browser. You should see the guestbook now displaying in your browser: ![Guestbook](../images/guestbook-page.png) Scenario 2: Deploy the application using Helm \u00b6 In this part of the lab, we will deploy the application by using Helm. We will set a release name of guestbook-demo to distinguish it from the previous deployment. The Helm chart is available here . Clone the Helm 101 repo to get the files: git clone https://github.com/IBM/helm101 A chart is defined as a collection of files that describe a related set of Kubernetes resources. We probably then should take a look at the the files before we go and install the chart. The files for the guestbook chart are as follows: . \u251c\u2500\u2500 Chart.yaml \\\\ A YAML file containing information about the chart \u251c\u2500\u2500 LICENSE \\\\ A plain text file containing the license for the chart \u251c\u2500\u2500 README.md \\\\ A README providing information about the chart usage, configuration, installation etc. \u251c\u2500\u2500 templates \\\\ A directory of templates that will generate valid Kubernetes manifest files when combined with values.yaml \u2502 \u251c\u2500\u2500 _helpers.tpl \\\\ Template helpers/definitions that are re-used throughout the chart \u2502 \u251c\u2500\u2500 guestbook-deployment.yaml \\\\ Guestbook app container resource \u2502 \u251c\u2500\u2500 guestbook-service.yaml \\\\ Guestbook app service resource \u2502 \u251c\u2500\u2500 NOTES.txt \\\\ A plain text file containing short usage notes about how to access the app post install \u2502 \u251c\u2500\u2500 redis-master-deployment.yaml \\\\ Redis master container resource \u2502 \u251c\u2500\u2500 redis-master-service.yaml \\\\ Redis master service resource \u2502 \u251c\u2500\u2500 redis-slave-deployment.yaml \\\\ Redis slave container resource \u2502 \u2514\u2500\u2500 redis-slave-service.yaml \\\\ Redis slave service resource \u2514\u2500\u2500 values.yaml \\\\ The default configuration values for the chart Note: The template files shown above will be rendered into Kubernetes manifest files before being passed to the Kubernetes API server. Therefore, they map to the manifest files that we deployed when we used kubectl (minus the helper and notes files). Let's go ahead and install the chart now. If the helm-demo namespace does not exist, you will need to create it using: kubectl create namespace helm-demo Install the app as a Helm chart: $ cd helm101/charts $ helm install guestbook-demo ./guestbook/ --namespace helm-demo NAME: guestbook-demo ... You should see output similar to the following: NAME: guestbook-demo LAST DEPLOYED: Mon Feb 24 18:08:02 2020 NAMESPACE: helm-demo STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: 1. Get the application URL by running these commands: NOTE: It may take a few minutes for the LoadBalancer IP to be available. You can watch the status of by running 'kubectl get svc -w guestbook-demo --namespace helm-demo' export SERVICE_IP=$(kubectl get svc --namespace helm-demo guestbook-demo -o jsonpath='{.status.loadBalancer.ingress[0].ip}') echo http://$SERVICE_IP:3000 The chart install performs the Kubernetes deployments and service creations of the redis master and slaves, and the guestbook app, as one. This is because the chart is a collection of files that describe a related set of Kubernetes resources and Helm manages the creation of these resources via the Kubernetes API. Check the deployment: kubectl get deployment guestbook-demo --namespace helm-demo You should see output similar to the following: $ kubectl get deployment guestbook-demo --namespace helm-dem NAME READY UP-TO-DATE AVAILABLE AGE guestbook-demo 2/2 2 2 51m To check the status of the running application pods, use: kubectl get pods --namespace helm-demo You should see output similar to the following: $ kubectl get pods --namespace helm-demo NAME READY STATUS RESTARTS AGE guestbook-demo-6c9cf8b9-jwbs9 1/1 Running 0 52m guestbook-demo-6c9cf8b9-qk4fb 1/1 Running 0 52m redis-master-5d8b66464f-j72jf 1/1 Running 0 52m redis-slave-586b4c847c-2xt99 1/1 Running 0 52m redis-slave-586b4c847c-q7rq5 1/1 Running 0 52m To check the services, use: kubectl get services --namespace helm-demo $ kubectl get services --namespace helm-demo NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE guestbook-demo LoadBalancer 172.21.43.244 <pending> 3000:31367/TCP 52m redis-master ClusterIP 172.21.12.43 <none> 6379/TCP 52m redis-slave ClusterIP 172.21.176.148 <none> 6379/TCP 52m View the guestbook: You can now play with the guestbook that you just created by opening it in a browser (it might take a few moments for the guestbook to come up). * **Local Host:** If you are running Kubernetes locally, view the guestbook by navigating to `http://localhost:3000` in your browser. * **Remote Host:** 1. To view the guestbook on a remote host, locate the external IP and the port of the load balancer by following the \"NOTES\" section in the install output. The commands will be similar to the following: ```console $ export SERVICE_IP=$(kubectl get svc --namespace helm-demo guestbook-demo -o jsonpath='{.status.loadBalancer.ingress[0].ip}') $ echo http://$SERVICE_IP http://50.23.5.136 ``` Combine the service IP with the port of the service printed earlier. In this scenario the URL is `http://50.23.5.136:31367`. Note: If no external IP is assigned, then you can get the external IP with the following command: ```console $ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME 10.47.122.98 Ready <none> 1h v1.10.11+IKS 173.193.92.112 Ubuntu 16.04.5 LTS 4.4.0-141-generic docker://18.6.1 ``` In this scenario the URL is `http://173.193.92.112:31367`. 2. Navigate to the output given (for example `http://50.23.5.136:31367`) in your browser. You should see the guestbook now displaying in your browser: ![Guestbook](../images/guestbook-page.png) Conclusion \u00b6 Congratulations, you have now deployed an application by using two different methods to Kubernetes! From this lab, you can see that using Helm required less commands and less to think about (by giving it the chart path and not the individual files) versus using kubectl . Helm's application management provides the user with this simplicity. Move on to the next lab, Lab2 , to learn how to update our running app when the chart has been changed.","title":"Lab 1. Deploy with Helm"},{"location":"Lab1/#lab-1-deploy-with-helm","text":"Let's investigate how Helm can help us focus on other things by letting a chart do the work for us. We'll first deploy an application to a Kubernetes cluster by using kubectl and then show how we can offload the work to a chart by deploying the same app with Helm. The application is the Guestbook App , which is a sample multi-tier web application.","title":"Lab 1. Deploy with Helm"},{"location":"Lab1/#scenario-1-deploy-the-application-using-kubectl","text":"In this part of the lab, we will deploy the application using the Kubernetes client kubectl . We will use Version 1 of the app for deploying here. If you already have a copy of the guestbook application installed from the kube101 lab , skip this section and go the helm example in Scenario 2 . Clone the Guestbook App repo to get the files: git clone https://github.com/IBM/guestbook.git Use the configuration files in the cloned Git repository to deploy the containers and create services for them by using the following commands: $ cd guestbook/v1 $ kubectl create -f redis-master-deployment.yaml deployment.apps/redis-master created $ kubectl create -f redis-master-service.yaml service/redis-master created $ kubectl create -f redis-slave-deployment.yaml deployment.apps/redis-slave created $ kubectl create -f redis-slave-service.yaml service/redis-slave created $ kubectl create -f guestbook-deployment.yaml deployment.apps/guestbook-v1 created $ kubectl create -f guestbook-service.yaml service/guestbook created Refer to the guestbook README for more details. View the guestbook: You can now play with the guestbook that you just created by opening it in a browser (it might take a few moments for the guestbook to come up). * **Local Host:** If you are running Kubernetes locally, view the guestbook by navigating to `http://localhost:3000` in your browser. * **Remote Host:** 1. To view the guestbook on a remote host, locate the external IP and port of the load balancer in the **EXTERNAL-IP** and **PORTS** columns of the `$ kubectl get services` output. ```console $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE guestbook LoadBalancer 172.21.252.107 50.23.5.136 3000:31838/TCP 14m redis-master ClusterIP 172.21.97.222 <none> 6379/TCP 14m redis-slave ClusterIP 172.21.43.70 <none> 6379/TCP 14m ......... ``` In this scenario the URL is `http://50.23.5.136:31838`. Note: If no external IP is assigned, then you can get the external IP with the following command: ```console $ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME 10.47.122.98 Ready <none> 1h v1.10.11+IKS 173.193.92.112 Ubuntu 16.04.5 LTS 4.4.0-141-generic docker://18.6.1 ``` In this scenario the URL is `http://173.193.92.112:31838`. 2. Navigate to the output given (for example `http://50.23.5.136:31838`) in your browser. You should see the guestbook now displaying in your browser: ![Guestbook](../images/guestbook-page.png)","title":"Scenario 1: Deploy the application using kubectl"},{"location":"Lab1/#scenario-2-deploy-the-application-using-helm","text":"In this part of the lab, we will deploy the application by using Helm. We will set a release name of guestbook-demo to distinguish it from the previous deployment. The Helm chart is available here . Clone the Helm 101 repo to get the files: git clone https://github.com/IBM/helm101 A chart is defined as a collection of files that describe a related set of Kubernetes resources. We probably then should take a look at the the files before we go and install the chart. The files for the guestbook chart are as follows: . \u251c\u2500\u2500 Chart.yaml \\\\ A YAML file containing information about the chart \u251c\u2500\u2500 LICENSE \\\\ A plain text file containing the license for the chart \u251c\u2500\u2500 README.md \\\\ A README providing information about the chart usage, configuration, installation etc. \u251c\u2500\u2500 templates \\\\ A directory of templates that will generate valid Kubernetes manifest files when combined with values.yaml \u2502 \u251c\u2500\u2500 _helpers.tpl \\\\ Template helpers/definitions that are re-used throughout the chart \u2502 \u251c\u2500\u2500 guestbook-deployment.yaml \\\\ Guestbook app container resource \u2502 \u251c\u2500\u2500 guestbook-service.yaml \\\\ Guestbook app service resource \u2502 \u251c\u2500\u2500 NOTES.txt \\\\ A plain text file containing short usage notes about how to access the app post install \u2502 \u251c\u2500\u2500 redis-master-deployment.yaml \\\\ Redis master container resource \u2502 \u251c\u2500\u2500 redis-master-service.yaml \\\\ Redis master service resource \u2502 \u251c\u2500\u2500 redis-slave-deployment.yaml \\\\ Redis slave container resource \u2502 \u2514\u2500\u2500 redis-slave-service.yaml \\\\ Redis slave service resource \u2514\u2500\u2500 values.yaml \\\\ The default configuration values for the chart Note: The template files shown above will be rendered into Kubernetes manifest files before being passed to the Kubernetes API server. Therefore, they map to the manifest files that we deployed when we used kubectl (minus the helper and notes files). Let's go ahead and install the chart now. If the helm-demo namespace does not exist, you will need to create it using: kubectl create namespace helm-demo Install the app as a Helm chart: $ cd helm101/charts $ helm install guestbook-demo ./guestbook/ --namespace helm-demo NAME: guestbook-demo ... You should see output similar to the following: NAME: guestbook-demo LAST DEPLOYED: Mon Feb 24 18:08:02 2020 NAMESPACE: helm-demo STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: 1. Get the application URL by running these commands: NOTE: It may take a few minutes for the LoadBalancer IP to be available. You can watch the status of by running 'kubectl get svc -w guestbook-demo --namespace helm-demo' export SERVICE_IP=$(kubectl get svc --namespace helm-demo guestbook-demo -o jsonpath='{.status.loadBalancer.ingress[0].ip}') echo http://$SERVICE_IP:3000 The chart install performs the Kubernetes deployments and service creations of the redis master and slaves, and the guestbook app, as one. This is because the chart is a collection of files that describe a related set of Kubernetes resources and Helm manages the creation of these resources via the Kubernetes API. Check the deployment: kubectl get deployment guestbook-demo --namespace helm-demo You should see output similar to the following: $ kubectl get deployment guestbook-demo --namespace helm-dem NAME READY UP-TO-DATE AVAILABLE AGE guestbook-demo 2/2 2 2 51m To check the status of the running application pods, use: kubectl get pods --namespace helm-demo You should see output similar to the following: $ kubectl get pods --namespace helm-demo NAME READY STATUS RESTARTS AGE guestbook-demo-6c9cf8b9-jwbs9 1/1 Running 0 52m guestbook-demo-6c9cf8b9-qk4fb 1/1 Running 0 52m redis-master-5d8b66464f-j72jf 1/1 Running 0 52m redis-slave-586b4c847c-2xt99 1/1 Running 0 52m redis-slave-586b4c847c-q7rq5 1/1 Running 0 52m To check the services, use: kubectl get services --namespace helm-demo $ kubectl get services --namespace helm-demo NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE guestbook-demo LoadBalancer 172.21.43.244 <pending> 3000:31367/TCP 52m redis-master ClusterIP 172.21.12.43 <none> 6379/TCP 52m redis-slave ClusterIP 172.21.176.148 <none> 6379/TCP 52m View the guestbook: You can now play with the guestbook that you just created by opening it in a browser (it might take a few moments for the guestbook to come up). * **Local Host:** If you are running Kubernetes locally, view the guestbook by navigating to `http://localhost:3000` in your browser. * **Remote Host:** 1. To view the guestbook on a remote host, locate the external IP and the port of the load balancer by following the \"NOTES\" section in the install output. The commands will be similar to the following: ```console $ export SERVICE_IP=$(kubectl get svc --namespace helm-demo guestbook-demo -o jsonpath='{.status.loadBalancer.ingress[0].ip}') $ echo http://$SERVICE_IP http://50.23.5.136 ``` Combine the service IP with the port of the service printed earlier. In this scenario the URL is `http://50.23.5.136:31367`. Note: If no external IP is assigned, then you can get the external IP with the following command: ```console $ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME 10.47.122.98 Ready <none> 1h v1.10.11+IKS 173.193.92.112 Ubuntu 16.04.5 LTS 4.4.0-141-generic docker://18.6.1 ``` In this scenario the URL is `http://173.193.92.112:31367`. 2. Navigate to the output given (for example `http://50.23.5.136:31367`) in your browser. You should see the guestbook now displaying in your browser: ![Guestbook](../images/guestbook-page.png)","title":"Scenario 2: Deploy the application using Helm"},{"location":"Lab1/#conclusion","text":"Congratulations, you have now deployed an application by using two different methods to Kubernetes! From this lab, you can see that using Helm required less commands and less to think about (by giving it the chart path and not the individual files) versus using kubectl . Helm's application management provides the user with this simplicity. Move on to the next lab, Lab2 , to learn how to update our running app when the chart has been changed.","title":"Conclusion"},{"location":"Lab2/","text":"Lab 2. Make changes with Helm \u00b6 In Lab 1 , we installed the guestbook sample app by using Helm and saw the benefits over using kubectl . You probably think that you're done and know enough to use Helm. But what about updates or improvements to the chart? How do you update your running app to pick up these changes? In this lab, we're going to look at how to update our running app when the chart has been changed. To demonstrate this, we're going to make changes to the original guestbook chart by: Removing the Redis slaves and using just the in-memory DB Changing the type from LoadBalancer to NodePort . It seems contrived but the goal of this lab is to show you how to update your apps with Kubernetes and Helm. So, how easy is it to do this? Let's take a look below. Scenario 1: Update the application using kubectl \u00b6 In this part of the lab we will update the previously deployed application Guestbook , using Kubernetes directly. This is an optional step that is not technically required to update your running app. The reason for doing this step is \"house keeping\" - you want to have the correct files for the current configuration that you have deployed. This avoids making mistakes if you have future updates or even rollbacks. In this updated configuration, we remove the Redis slaves. To have the directory match the configuration, move/archive or simply remove the Redis slave files from the guestbook repo tree: cd guestbook/v1 rm redis-slave-service.yaml rm redis-slave-deployment.yaml Note: you can reclaim these files later with a git checkout -- <filename> command, if desired Delete the Redis slave service and pods: $ kubectl delete svc redis-slave --namespace default service \"redis-slave\" deleted $ kubectl delete deployment redis-slave --namespace default deployment.extensions \"redis-slave\" deleted Update the guestbook service from LoadBalancer to NodePort type: sed -i.bak 's/LoadBalancer/NodePort/g' guestbook-service.yaml Note: you can reset the files later with a git checkout -- <filename> command, if desired Delete the guestbook service: kubectl delete svc guestbook --namespace default Re-create the service with NodePort type: kubectl create -f guestbook-service.yaml Check the updates, using kubectl get all --namespace default $ kubectl get all --namespace default NAME READY STATUS RESTARTS AGE pod/guestbook-v1-7fc76dc46-9r4s7 1/1 Running 0 1h pod/guestbook-v1-7fc76dc46-hspnk 1/1 Running 0 1h pod/guestbook-v1-7fc76dc46-sxzkt 1/1 Running 0 1h pod/redis-master-5d8b66464f-pvbl9 1/1 Running 0 1h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook NodePort 172.21.45.29 <none> 3000:31989/TCP 31s service/kubernetes ClusterIP 172.21.0.1 <none> 443/TCP 9d service/redis-master ClusterIP 172.21.232.61 <none> 6379/TCP 1h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-demo 3/3 3 3 1h deployment.apps/redis-master 1/1 1 1 1h NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-v1-7fc76dc46 3 3 3 1h replicaset.apps/redis-master-5d8b66464f 1 1 1 1h Note: The service type has changed (to NodePort ) and a new port has been allocated ( 31989 in this output case) to the guestbook service. All redis-slave resources have been removed. View the guestbook Get the public IP of one of your nodes: kubectl get nodes -o wide Navigate to the IP address plus the node port that printed earlier. Scenario 2: Update the application using Helm \u00b6 In this section, we'll update the previously deployed guestbook-demo application by using Helm. Before we start, let's take a few minutes to see how Helm simplifies the process compared to using Kubernetes directly. Helm's use of a template language provides great flexibility and power to chart authors, which removes the complexity to the chart user. In the guestbook example, we'll use the following capabilities of templating: Values: An object that provides access to the values passed into the chart. An example of this is in guestbook-service , which contains the line type: {{ .Values.service.type }} . This line provides the capability to set the service type during an upgrade or install. Control structures: Also called \u201cactions\u201d in template parlance, control structures provide the template author with the ability to control the flow of a template\u2019s generation. An example of this is in redis-slave-service , which contains the line {{- if .Values.redis.slaveEnabled -}} . This line allows us to enable/disable the REDIS master/slave during an upgrade or install. The complete redis-slave-service.yaml file shown below, demonstrates how the file becomes redundant when the slaveEnabled flag is disabled and also how the port value is set. There are more examples of templating functionality in the other chart files. {{ - if .Values.redis.slaveEnabled - }} apiVersion : v1 kind : Service metadata : name : redis-slave labels : app : redis role : slave spec : ports : - port : {{ .Values.redis.port }} targetPort : redis-server selector : app : redis role : slave {{ - end }} Enough talking about the theory. Now let's give it a go! First, lets check the app we deployed in Lab 1 with Helm. This can be done by checking the Helm releases: helm list -n helm-demo Note that we specify the namespace. If not specified, it uses the current namespace context. You should see output similar to the following: $ helm list -n helm-demo NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION guestbook-demo helm-demo 1 2020-02-24 18:08:02.017401264 +0000 UTC deployed guestbook-0.2.0 The list command provides the list of deployed charts (releases) giving information of chart version, namespace, number of updates (revisions) etc. We now know the release is there from step 1., so we can update the application: $ cd helm101/charts $ helm upgrade guestbook-demo ./guestbook --set redis.slaveEnabled = false,service.type = NodePort --namespace helm-demo Release \"guestbook-demo\" has been upgraded. Happy Helming! ... A Helm upgrade takes an existing release and upgrades it according to the information you provide. You should see output similar to the following: $ helm upgrade guestbook-demo ./guestbook --set redis.slaveEnabled = false,service.type = NodePort --namespace helm-demo Release \"guestbook-demo\" has been upgraded. Happy Helming! NAME: guestbook-demo LAST DEPLOYED: Tue Feb 25 14:23:27 2020 NAMESPACE: helm-demo STATUS: deployed REVISION: 2 TEST SUITE: None NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace helm-demo -o jsonpath=\"{.spec.ports[0].nodePort}\" services guestbook-demo) export NODE_IP=$(kubectl get nodes --namespace helm-demo -o jsonpath=\"{.items[0].status.addresses[0].address}\") echo http://$NODE_IP:$NODE_PORT The upgrade command upgrades the app to a specified version of a chart, removes the redis-slave resources, and updates the app service.type to NodePort . Check the updates, using kubectl get all --namespace helm-demo : $ kubectl get all --namespace helm-demo NAME READY STATUS RESTARTS AGE pod/guestbook-demo-6c9cf8b9-dhqk9 1/1 Running 0 20h pod/guestbook-demo-6c9cf8b9-zddn2 1/1 Running 0 20h pod/redis-master-5d8b66464f-g7sh6 1/1 Running 0 20h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook-demo NodePort 172.21.43.244 <none> 3000:31202/TCP 20h service/redis-master ClusterIP 172.21.12.43 <none> 6379/TCP 20h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-demo 2/2 2 2 20h deployment.apps/redis-master 1/1 1 1 20h NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-demo-6c9cf8b9 2 2 2 20h replicaset.apps/redis-master-5d8b66464f 1 1 1 20h Note: The service type has changed (to NodePort ) and a new port has been allocated ( 31202 in this output case) to the guestbook service. All redis-slave resources have been removed. When you check the Helm release with helm list -n helm-demo , you will see the revision and date has been updated: $ helm list -n helm-demo NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION guestbook-demo helm-demo 2 2020-02-25 14:23:27.06732381 +0000 UTC deployed guestbook-0.2.0 View the guestbook Get the public IP of one of your nodes: kubectl get nodes -o wide Navigate to the IP address plus the node port that printed earlier. Conclusion \u00b6 Congratulations, you have now updated the applications! Helm does not require any manual changing of resources and is therefore so much easier to upgrade! All configurations can be set on the fly on the command line or by using override files. This is made possible from when the logic was added to the template files, which enables or disables the capability, depending on the flag set. Check out Lab 3 to get an insight into revision management.","title":"Lab 2. Make changes with Helm"},{"location":"Lab2/#lab-2-make-changes-with-helm","text":"In Lab 1 , we installed the guestbook sample app by using Helm and saw the benefits over using kubectl . You probably think that you're done and know enough to use Helm. But what about updates or improvements to the chart? How do you update your running app to pick up these changes? In this lab, we're going to look at how to update our running app when the chart has been changed. To demonstrate this, we're going to make changes to the original guestbook chart by: Removing the Redis slaves and using just the in-memory DB Changing the type from LoadBalancer to NodePort . It seems contrived but the goal of this lab is to show you how to update your apps with Kubernetes and Helm. So, how easy is it to do this? Let's take a look below.","title":"Lab 2. Make changes with Helm"},{"location":"Lab2/#scenario-1-update-the-application-using-kubectl","text":"In this part of the lab we will update the previously deployed application Guestbook , using Kubernetes directly. This is an optional step that is not technically required to update your running app. The reason for doing this step is \"house keeping\" - you want to have the correct files for the current configuration that you have deployed. This avoids making mistakes if you have future updates or even rollbacks. In this updated configuration, we remove the Redis slaves. To have the directory match the configuration, move/archive or simply remove the Redis slave files from the guestbook repo tree: cd guestbook/v1 rm redis-slave-service.yaml rm redis-slave-deployment.yaml Note: you can reclaim these files later with a git checkout -- <filename> command, if desired Delete the Redis slave service and pods: $ kubectl delete svc redis-slave --namespace default service \"redis-slave\" deleted $ kubectl delete deployment redis-slave --namespace default deployment.extensions \"redis-slave\" deleted Update the guestbook service from LoadBalancer to NodePort type: sed -i.bak 's/LoadBalancer/NodePort/g' guestbook-service.yaml Note: you can reset the files later with a git checkout -- <filename> command, if desired Delete the guestbook service: kubectl delete svc guestbook --namespace default Re-create the service with NodePort type: kubectl create -f guestbook-service.yaml Check the updates, using kubectl get all --namespace default $ kubectl get all --namespace default NAME READY STATUS RESTARTS AGE pod/guestbook-v1-7fc76dc46-9r4s7 1/1 Running 0 1h pod/guestbook-v1-7fc76dc46-hspnk 1/1 Running 0 1h pod/guestbook-v1-7fc76dc46-sxzkt 1/1 Running 0 1h pod/redis-master-5d8b66464f-pvbl9 1/1 Running 0 1h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook NodePort 172.21.45.29 <none> 3000:31989/TCP 31s service/kubernetes ClusterIP 172.21.0.1 <none> 443/TCP 9d service/redis-master ClusterIP 172.21.232.61 <none> 6379/TCP 1h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-demo 3/3 3 3 1h deployment.apps/redis-master 1/1 1 1 1h NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-v1-7fc76dc46 3 3 3 1h replicaset.apps/redis-master-5d8b66464f 1 1 1 1h Note: The service type has changed (to NodePort ) and a new port has been allocated ( 31989 in this output case) to the guestbook service. All redis-slave resources have been removed. View the guestbook Get the public IP of one of your nodes: kubectl get nodes -o wide Navigate to the IP address plus the node port that printed earlier.","title":"Scenario 1: Update the application using kubectl"},{"location":"Lab2/#scenario-2-update-the-application-using-helm","text":"In this section, we'll update the previously deployed guestbook-demo application by using Helm. Before we start, let's take a few minutes to see how Helm simplifies the process compared to using Kubernetes directly. Helm's use of a template language provides great flexibility and power to chart authors, which removes the complexity to the chart user. In the guestbook example, we'll use the following capabilities of templating: Values: An object that provides access to the values passed into the chart. An example of this is in guestbook-service , which contains the line type: {{ .Values.service.type }} . This line provides the capability to set the service type during an upgrade or install. Control structures: Also called \u201cactions\u201d in template parlance, control structures provide the template author with the ability to control the flow of a template\u2019s generation. An example of this is in redis-slave-service , which contains the line {{- if .Values.redis.slaveEnabled -}} . This line allows us to enable/disable the REDIS master/slave during an upgrade or install. The complete redis-slave-service.yaml file shown below, demonstrates how the file becomes redundant when the slaveEnabled flag is disabled and also how the port value is set. There are more examples of templating functionality in the other chart files. {{ - if .Values.redis.slaveEnabled - }} apiVersion : v1 kind : Service metadata : name : redis-slave labels : app : redis role : slave spec : ports : - port : {{ .Values.redis.port }} targetPort : redis-server selector : app : redis role : slave {{ - end }} Enough talking about the theory. Now let's give it a go! First, lets check the app we deployed in Lab 1 with Helm. This can be done by checking the Helm releases: helm list -n helm-demo Note that we specify the namespace. If not specified, it uses the current namespace context. You should see output similar to the following: $ helm list -n helm-demo NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION guestbook-demo helm-demo 1 2020-02-24 18:08:02.017401264 +0000 UTC deployed guestbook-0.2.0 The list command provides the list of deployed charts (releases) giving information of chart version, namespace, number of updates (revisions) etc. We now know the release is there from step 1., so we can update the application: $ cd helm101/charts $ helm upgrade guestbook-demo ./guestbook --set redis.slaveEnabled = false,service.type = NodePort --namespace helm-demo Release \"guestbook-demo\" has been upgraded. Happy Helming! ... A Helm upgrade takes an existing release and upgrades it according to the information you provide. You should see output similar to the following: $ helm upgrade guestbook-demo ./guestbook --set redis.slaveEnabled = false,service.type = NodePort --namespace helm-demo Release \"guestbook-demo\" has been upgraded. Happy Helming! NAME: guestbook-demo LAST DEPLOYED: Tue Feb 25 14:23:27 2020 NAMESPACE: helm-demo STATUS: deployed REVISION: 2 TEST SUITE: None NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace helm-demo -o jsonpath=\"{.spec.ports[0].nodePort}\" services guestbook-demo) export NODE_IP=$(kubectl get nodes --namespace helm-demo -o jsonpath=\"{.items[0].status.addresses[0].address}\") echo http://$NODE_IP:$NODE_PORT The upgrade command upgrades the app to a specified version of a chart, removes the redis-slave resources, and updates the app service.type to NodePort . Check the updates, using kubectl get all --namespace helm-demo : $ kubectl get all --namespace helm-demo NAME READY STATUS RESTARTS AGE pod/guestbook-demo-6c9cf8b9-dhqk9 1/1 Running 0 20h pod/guestbook-demo-6c9cf8b9-zddn2 1/1 Running 0 20h pod/redis-master-5d8b66464f-g7sh6 1/1 Running 0 20h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook-demo NodePort 172.21.43.244 <none> 3000:31202/TCP 20h service/redis-master ClusterIP 172.21.12.43 <none> 6379/TCP 20h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-demo 2/2 2 2 20h deployment.apps/redis-master 1/1 1 1 20h NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-demo-6c9cf8b9 2 2 2 20h replicaset.apps/redis-master-5d8b66464f 1 1 1 20h Note: The service type has changed (to NodePort ) and a new port has been allocated ( 31202 in this output case) to the guestbook service. All redis-slave resources have been removed. When you check the Helm release with helm list -n helm-demo , you will see the revision and date has been updated: $ helm list -n helm-demo NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION guestbook-demo helm-demo 2 2020-02-25 14:23:27.06732381 +0000 UTC deployed guestbook-0.2.0 View the guestbook Get the public IP of one of your nodes: kubectl get nodes -o wide Navigate to the IP address plus the node port that printed earlier.","title":"Scenario 2: Update the application using Helm"},{"location":"Lab2/#conclusion","text":"Congratulations, you have now updated the applications! Helm does not require any manual changing of resources and is therefore so much easier to upgrade! All configurations can be set on the fly on the command line or by using override files. This is made possible from when the logic was added to the template files, which enables or disables the capability, depending on the flag set. Check out Lab 3 to get an insight into revision management.","title":"Conclusion"},{"location":"Lab3/","text":"Lab 3. Keeping track of the deployed application \u00b6 Let's say you deployed different release versions of your application (i.e., you upgraded the running application). How do you keep track of the versions and how can you do a rollback? Scenario 1: Revision management using Kubernetes \u00b6 In this part of the lab, we should illustrate revision management of guestbook by using Kubernetes directly, but we can't. This is because Kubernetes does not provide any support for revision management. The onus is on you to manage your systems and any updates or changes you make. However, we can use Helm to conduct revision management. Scenario 2: Revision management using Helm \u00b6 In this part of the lab, we illustrate revision management on the deployed application guestbook-demo by using Helm. With Helm, every time an install, upgrade, or rollback happens, the revision number is incremented by 1. The first revision number is always 1. Helm persists release metadata in Secrets (default) or ConfigMaps, stored in the Kubernetes cluster. Every time your release changes, it appends that to the existing data. This provides Helm with the capability to rollback to a previous release. Let's see how this works in practice. Check the number of deployments: helm history guestbook-demo -n helm-demo You should see output similar to the following because we did an upgrade in Lab 2 after the initial install in Lab 1 : $ helm history guestbook-demo -n helm-demo REVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Mon Feb 24 18:08:02 2020 superseded guestbook-0.2.0 Install complete 2 Tue Feb 25 14:23:27 2020 deployed guestbook-0.2.0 Upgrade complete Roll back to the previous revision: In this rollback, Helm checks the changes that occured when upgrading from the revision 1 to revision 2. This information enables it to makes the calls to the Kubernetes API server, to update the deployed application as per the initial deployment - in other words with Redis slaves and using a load balancer. Rollback with this command: helm rollback guestbook-demo 1 -n helm-demo $ helm rollback guestbook-demo 1 -n helm-demo Rollback was a success! Happy Helming! Check the history again: helm history guestbook-demo -n helm-demo You should see output similar to the following: $ helm history guestbook-demo -n helm-demo REVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Mon Feb 24 18:08:02 2020 superseded guestbook-0.2.0 Install complete 2 Tue Feb 25 14:23:27 2020 superseded guestbook-0.2.0 Upgrade complete 3 Tue Feb 25 14:53:45 2020 deployed guestbook-0.2.0 Rollback to 1 Check the rollback, using: kubectl get all --namespace helm-demo $ kubectl get all --namespace helm-demo NAME READY STATUS RESTARTS AGE pod/guestbook-demo-6c9cf8b9-dhqk9 1/1 Running 0 20h pod/guestbook-demo-6c9cf8b9-zddn 1/1 Running 0 20h pod/redis-master-5d8b66464f-g7sh6 1/1 Running 0 20h pod/redis-slave-586b4c847c-tkfj5 1/1 Running 0 5m15s pod/redis-slave-586b4c847c-xxrdn 1/1 Running 0 5m15s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook-demo LoadBalancer 172.21.43.244 <pending> 3000:31202/TCP 20h service/redis-master ClusterIP 172.21.12.43 <none> 6379/TCP 20h service/redis-slave ClusterIP 172.21.232.16 <none> 6379/TCP 5m15s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-demo 2/2 2 2 20h deployment.apps/redis-master 1/1 1 1 20h deployment.apps/redis-slave 2/2 2 2 5m15s NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-demo-26c9cf8b9 2 2 2 20h replicaset.apps/redis-master-5d8b66464f 1 1 1 20h replicaset.apps/redis-slave-586b4c847c 2 2 2 5m15s You can see from the output that the app service is the service type of LoadBalancer again and the Redis master/slave deployment has returned. This shows a complete rollback from the upgrade in Lab 2 Conclusion \u00b6 From this lab, we can say that Helm does revision management well and Kubernetes does not have the capability built in! You might be wondering why we need helm rollback when you could just re-run the helm upgrade from a previous version. And that's a good question. Technically, you should end up with the same resources (with same parameters) deployed. However, the advantage of using helm rollback is that helm manages (ie. remembers) all of the variations/parameters of the previous helm install\\upgrade for you. Doing the rollback via a helm upgrade requires you (and your entire team) to manually track how the command was previously executed. That's not only tedious but very error prone. It is much easier, safer and reliable to let Helm manage all of that for you and all you need to do it tell it which previous version to go back to, and it does the rest. Lab 4 awaits.","title":"Lab 3. Keeping track of the deployed application"},{"location":"Lab3/#lab-3-keeping-track-of-the-deployed-application","text":"Let's say you deployed different release versions of your application (i.e., you upgraded the running application). How do you keep track of the versions and how can you do a rollback?","title":"Lab 3. Keeping track of the deployed application"},{"location":"Lab3/#scenario-1-revision-management-using-kubernetes","text":"In this part of the lab, we should illustrate revision management of guestbook by using Kubernetes directly, but we can't. This is because Kubernetes does not provide any support for revision management. The onus is on you to manage your systems and any updates or changes you make. However, we can use Helm to conduct revision management.","title":"Scenario 1: Revision management using Kubernetes"},{"location":"Lab3/#scenario-2-revision-management-using-helm","text":"In this part of the lab, we illustrate revision management on the deployed application guestbook-demo by using Helm. With Helm, every time an install, upgrade, or rollback happens, the revision number is incremented by 1. The first revision number is always 1. Helm persists release metadata in Secrets (default) or ConfigMaps, stored in the Kubernetes cluster. Every time your release changes, it appends that to the existing data. This provides Helm with the capability to rollback to a previous release. Let's see how this works in practice. Check the number of deployments: helm history guestbook-demo -n helm-demo You should see output similar to the following because we did an upgrade in Lab 2 after the initial install in Lab 1 : $ helm history guestbook-demo -n helm-demo REVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Mon Feb 24 18:08:02 2020 superseded guestbook-0.2.0 Install complete 2 Tue Feb 25 14:23:27 2020 deployed guestbook-0.2.0 Upgrade complete Roll back to the previous revision: In this rollback, Helm checks the changes that occured when upgrading from the revision 1 to revision 2. This information enables it to makes the calls to the Kubernetes API server, to update the deployed application as per the initial deployment - in other words with Redis slaves and using a load balancer. Rollback with this command: helm rollback guestbook-demo 1 -n helm-demo $ helm rollback guestbook-demo 1 -n helm-demo Rollback was a success! Happy Helming! Check the history again: helm history guestbook-demo -n helm-demo You should see output similar to the following: $ helm history guestbook-demo -n helm-demo REVISION UPDATED STATUS CHART APP VERSION DESCRIPTION 1 Mon Feb 24 18:08:02 2020 superseded guestbook-0.2.0 Install complete 2 Tue Feb 25 14:23:27 2020 superseded guestbook-0.2.0 Upgrade complete 3 Tue Feb 25 14:53:45 2020 deployed guestbook-0.2.0 Rollback to 1 Check the rollback, using: kubectl get all --namespace helm-demo $ kubectl get all --namespace helm-demo NAME READY STATUS RESTARTS AGE pod/guestbook-demo-6c9cf8b9-dhqk9 1/1 Running 0 20h pod/guestbook-demo-6c9cf8b9-zddn 1/1 Running 0 20h pod/redis-master-5d8b66464f-g7sh6 1/1 Running 0 20h pod/redis-slave-586b4c847c-tkfj5 1/1 Running 0 5m15s pod/redis-slave-586b4c847c-xxrdn 1/1 Running 0 5m15s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook-demo LoadBalancer 172.21.43.244 <pending> 3000:31202/TCP 20h service/redis-master ClusterIP 172.21.12.43 <none> 6379/TCP 20h service/redis-slave ClusterIP 172.21.232.16 <none> 6379/TCP 5m15s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-demo 2/2 2 2 20h deployment.apps/redis-master 1/1 1 1 20h deployment.apps/redis-slave 2/2 2 2 5m15s NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-demo-26c9cf8b9 2 2 2 20h replicaset.apps/redis-master-5d8b66464f 1 1 1 20h replicaset.apps/redis-slave-586b4c847c 2 2 2 5m15s You can see from the output that the app service is the service type of LoadBalancer again and the Redis master/slave deployment has returned. This shows a complete rollback from the upgrade in Lab 2","title":"Scenario 2: Revision management using Helm"},{"location":"Lab3/#conclusion","text":"From this lab, we can say that Helm does revision management well and Kubernetes does not have the capability built in! You might be wondering why we need helm rollback when you could just re-run the helm upgrade from a previous version. And that's a good question. Technically, you should end up with the same resources (with same parameters) deployed. However, the advantage of using helm rollback is that helm manages (ie. remembers) all of the variations/parameters of the previous helm install\\upgrade for you. Doing the rollback via a helm upgrade requires you (and your entire team) to manually track how the command was previously executed. That's not only tedious but very error prone. It is much easier, safer and reliable to let Helm manage all of that for you and all you need to do it tell it which previous version to go back to, and it does the rest. Lab 4 awaits.","title":"Conclusion"},{"location":"Lab4/","text":"Lab 4. Share Helm Charts \u00b6 A key aspect of providing an application means sharing with others. Sharing can be direct counsumption (by users or in CI/CD pipelines) or as a dependency for other charts. If people can't find your app then they can't use it. A means of sharing is a chart repository, which is a location where packaged charts can be stored and shared. As the chart repository only applies to Helm, we will just look at the usage and storage of Helm charts. Using charts from a public repository \u00b6 Helm charts can be available on a remote repository or in a local environment/repository. The remote repositories can be public like Bitnami Charts or IBM Helm Charts , or hosted repositories like on Google Cloud Storage or GitHub. Refer to Helm Chart Repository Guide for more details. You can learn more about the structure of a chart repository by examining the chart index file in this lab. In this part of the lab, we show you how to install the guestbook chart from the Helm101 repo . Check the repositories configured on your system: helm repo list The output should be similar to the following: $ helm repo list Error: no repositories to show Note: Chart repositories are not installed by default with Helm v3. It is expected that you add the repositories for the charts you want to use. The Helm Hub provides a centralized search for publicly available distributed charts. Using the hub you can identify the chart with its hosted repository and then add it to your local respoistory list. The Helm chart repository like Helm v2 is in \"maintenance mode\" and will be deprecated by November 13, 2020. See the project status for more details. Add helm101 repo: helm repo add helm101 https://ibm.github.io/helm101/ Should generate an output as follows: $ helm repo add helm101 https://ibm.github.io/helm101/ \"helm101\" has been added to your repositories You can also search your repositories for charts by running the following command: helm search repo helm101 $ helm search repo helm101 NAME CHART VERSION APP VERSION DESCRIPTION helm101/guestbook 0.2.1 A Helm chart to deploy Guestbook three tier web... Install the chart As mentioned we are going to install the guestbook chart from the Helm101 repo . As the repo is added to our local respoitory list we can reference the chart using the repo name/chart name , in other words helm101/guestbook . To see this in action, you will install the application to a new namespace called repo-demo . If the repo-demo namespace does not exist, create it using: kubectl create namespace repo-demo Now install the chart using this command: helm install guestbook-demo helm101/guestbook --namespace repo-demo The output should be similar to the following: $ helm install guestbook-demo helm101/guestbook --namespace repo-demo NAME: guestbook-demo LAST DEPLOYED: Tue Feb 25 15:40:17 2020 NAMESPACE: repo-demo STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: 1. Get the application URL by running these commands: NOTE: It may take a few minutes for the LoadBalancer IP to be available. You can watch the status of by running 'kubectl get svc -w guestbook-demo --namespace repo-demo' export SERVICE_IP=$(kubectl get svc --namespace repo-demo guestbook-demo -o jsonpath='{.status.loadBalancer.ingress[0].ip}') echo http://$SERVICE_IP:3000 Check that release deployed as expected as follows: $ helm list -n repo-demo NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION guestbook-demo repo-demo 1 2020-02-25 15:40:17.627745329 +0000 UTC deployed guestbook-0.2.1 Conclusion \u00b6 This lab provided you with a brief introduction to the Helm repositories to show how charts can be installed. The ability to share your chart means ease of use to both you and your consumers.","title":"Lab 4. Share Helm Charts"},{"location":"Lab4/#lab-4-share-helm-charts","text":"A key aspect of providing an application means sharing with others. Sharing can be direct counsumption (by users or in CI/CD pipelines) or as a dependency for other charts. If people can't find your app then they can't use it. A means of sharing is a chart repository, which is a location where packaged charts can be stored and shared. As the chart repository only applies to Helm, we will just look at the usage and storage of Helm charts.","title":"Lab 4. Share Helm Charts"},{"location":"Lab4/#using-charts-from-a-public-repository","text":"Helm charts can be available on a remote repository or in a local environment/repository. The remote repositories can be public like Bitnami Charts or IBM Helm Charts , or hosted repositories like on Google Cloud Storage or GitHub. Refer to Helm Chart Repository Guide for more details. You can learn more about the structure of a chart repository by examining the chart index file in this lab. In this part of the lab, we show you how to install the guestbook chart from the Helm101 repo . Check the repositories configured on your system: helm repo list The output should be similar to the following: $ helm repo list Error: no repositories to show Note: Chart repositories are not installed by default with Helm v3. It is expected that you add the repositories for the charts you want to use. The Helm Hub provides a centralized search for publicly available distributed charts. Using the hub you can identify the chart with its hosted repository and then add it to your local respoistory list. The Helm chart repository like Helm v2 is in \"maintenance mode\" and will be deprecated by November 13, 2020. See the project status for more details. Add helm101 repo: helm repo add helm101 https://ibm.github.io/helm101/ Should generate an output as follows: $ helm repo add helm101 https://ibm.github.io/helm101/ \"helm101\" has been added to your repositories You can also search your repositories for charts by running the following command: helm search repo helm101 $ helm search repo helm101 NAME CHART VERSION APP VERSION DESCRIPTION helm101/guestbook 0.2.1 A Helm chart to deploy Guestbook three tier web... Install the chart As mentioned we are going to install the guestbook chart from the Helm101 repo . As the repo is added to our local respoitory list we can reference the chart using the repo name/chart name , in other words helm101/guestbook . To see this in action, you will install the application to a new namespace called repo-demo . If the repo-demo namespace does not exist, create it using: kubectl create namespace repo-demo Now install the chart using this command: helm install guestbook-demo helm101/guestbook --namespace repo-demo The output should be similar to the following: $ helm install guestbook-demo helm101/guestbook --namespace repo-demo NAME: guestbook-demo LAST DEPLOYED: Tue Feb 25 15:40:17 2020 NAMESPACE: repo-demo STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: 1. Get the application URL by running these commands: NOTE: It may take a few minutes for the LoadBalancer IP to be available. You can watch the status of by running 'kubectl get svc -w guestbook-demo --namespace repo-demo' export SERVICE_IP=$(kubectl get svc --namespace repo-demo guestbook-demo -o jsonpath='{.status.loadBalancer.ingress[0].ip}') echo http://$SERVICE_IP:3000 Check that release deployed as expected as follows: $ helm list -n repo-demo NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION guestbook-demo repo-demo 1 2020-02-25 15:40:17.627745329 +0000 UTC deployed guestbook-0.2.1","title":"Using charts from a public repository"},{"location":"Lab4/#conclusion","text":"This lab provided you with a brief introduction to the Helm repositories to show how charts can be installed. The ability to share your chart means ease of use to both you and your consumers.","title":"Conclusion"}]}